{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking configuration parameter values from config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the configurations from config.json file.\n",
    "import json\n",
    "with open(\"config.json\") as file:\n",
    "    build_parameters = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "pipeline_output_bucket = build_parameters[\"output_bucket\"] \n",
    "sagemaker_session = sagemaker.session.Session(default_bucket = pipeline_output_bucket)\n",
    "# sagemaker_session = sagemaker.session.Session()\n",
    "# role = sagemaker.get_execution_role()\n",
    "role = \"arn:aws:iam::852619674999:role/service-role/AmazonSageMaker-ExecutionRole-20220427T124311\"\n",
    "\n",
    "print(role)\n",
    "print(sagemaker_session.default_bucket())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting the subfolder pattern\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "year = now.year\n",
    "month = now.month\n",
    "if month < 10:\n",
    "    month = f\"0{month}\"\n",
    "day = now.day\n",
    "if day < 10:\n",
    "    day = f\"0{day}\"\n",
    "subfolder_pattern = f\"{year}{month}{day}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_bucket = build_parameters[\"input_bucket\"]\n",
    "\n",
    "y_actual = f\"s3://{build_parameters['input_bucket']}/churn-bigml-20.csv\"\n",
    "\n",
    "# import s3fs\n",
    "# s3 = s3fs.S3FileSystem(anon=False)\n",
    "# scoring_output_location = f\"s3://{build_parameters['output_bucket']}/Scoring_Pipeline_Output/{subfolder_pattern}-*/InferenceOutput/*.csv\"\n",
    "# y_predicted = f\"s3://{s3.glob(scoring_output_location)[0]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "# framework_version = \"0.23-1\"\n",
    "framework_version = build_parameters[\"sklearn_processor_framework_version\"]\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "#     framework_version = processing_framework_sklearn_version,\n",
    "    framework_version = framework_version,\n",
    "    instance_type = build_parameters[\"processing_instance_type\"],\n",
    "    instance_count= build_parameters[\"processing_instance_count\"],\n",
    "    base_job_name = f\"{build_parameters['usecase']}-preprocessing\",\n",
    "    role=role\n",
    ")\n",
    "\n",
    "\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "    \n",
    "\n",
    "step_monitoring = ProcessingStep(\n",
    "    name = \"comparing-actual-vs-predicted\",\n",
    "    description = \"Comparing actual and predicted to generate model performance metrics\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source =  y_actual, destination=\"/opt/ml/processing/input/actual\"),  \n",
    "        # ProcessingInput(source= y_predicted, destination=\"/opt/ml/processing/input/predicted\"),\n",
    "        # ProcessingInput(source = f\"s3://{pipeline_output_bucket}/Monitoring_Output/Monitor.csv\", destination = \"/opt/ml/processing/input/metrics\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name = \"metrics\", source=\"/opt/ml/processing/input/metrics_output\", destination = f\"s3://{pipeline_output_bucket}/Monitoring_Output\")\n",
    "    ],\n",
    "    code = f\"s3://{build_parameters['input_bucket']}/codes/{build_parameters['monitoring_code_file_name']}\",\n",
    "    job_arguments = [\"--y_actual_location\", \"/opt/ml/processing/input/actual\", \"--y_predicted_location\", \n",
    "                     # \"/opt/ml/processing/input/predicted\",\n",
    "                     f\"s3://{build_parameters['output_bucket']}/Scoring_Pipeline_Output/{subfolder_pattern}-*/InferenceOutput/*.csv\",\n",
    "                     \"metrics_input_location\", f\"s3://{pipeline_output_bucket}/Monitoring_Output/Monitor.csv\",\n",
    "                     \"--metrics_output_location\", \"/opt/ml/processing/input/metrics_output\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sending Mail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.lambda_helper import Lambda\n",
    "from sagemaker.workflow.lambda_step import (\n",
    "    LambdaStep,\n",
    "    LambdaOutput,\n",
    "    LambdaOutputTypeEnum,\n",
    ")\n",
    "\n",
    "func = Lambda(\n",
    "    function_arn = \"arn:aws:lambda:ap-south-1:852619674999:function:model_performance_notification\",\n",
    "    handler = \"monitoring.lambda_handler\"\n",
    ")\n",
    "step_deploy_lambda = LambdaStep(\n",
    "    name=\"SendMail\",\n",
    "    lambda_func = func,\n",
    "    inputs={\n",
    "        # \"performance_file_location\":f\"s3://{pipeline_output_bucket}/Monitoring_Output/Monitor.csv\",\n",
    "        \"performance_file_location\":step_monitoring.properties.ProcessingOutputConfig.Outputs[\"metrics\"].S3Output.S3Uri,\n",
    "        \"sns_topic_name\":\"arn:aws:sns:ap-south-1:852619674999:Approvals\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arranging the steps inside pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "# pipeline_name = f\"{usecase}-training\"\n",
    "pipeline = Pipeline(\n",
    "    name=\"Churn-Monitoring\",\n",
    "    steps = [step_monitoring, \n",
    "             # step_deploy_lambda\n",
    "            ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
