{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking configuration parameter values from config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the configurations from config.json file.\n",
    "import json\n",
    "with open(\"config.json\") as file:\n",
    "    build_parameters = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::852619674999:role/service-role/AmazonSageMaker-ExecutionRole-20220427T124311\n",
      "mloutput-churn-telecomchurn-852619674999-ap-south-1\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "pipeline_output_bucket = build_parameters[\"output_bucket\"] \n",
    "sagemaker_session = sagemaker.session.Session(default_bucket = pipeline_output_bucket)\n",
    "# sagemaker_session = sagemaker.session.Session()\n",
    "# role = sagemaker.get_execution_role()\n",
    "role = \"arn:aws:iam::852619674999:role/service-role/AmazonSageMaker-ExecutionRole-20220427T124311\"\n",
    "\n",
    "print(role)\n",
    "print(sagemaker_session.default_bucket())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_bucket = build_parameters[\"input_bucket\"]\n",
    "batch_data_file_name = build_parameters[\"scoring_data_file_name\"]\n",
    "batch_data_uri = f\"s3://{input_bucket}/{batch_data_file_name}\"\n",
    "# batch_data_uri = build_parameters[\"scoring_data_s3_location\"]\n",
    "\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString\n",
    "\n",
    "batch_data = ParameterString(name=\"BatchData\", default_value=batch_data_uri)\n",
    "feature_selection_file_name = build_parameters[\"feature_selection_file_name\"]\n",
    "# input_feature_selection_file_uri = build_parameters[\"feature_selection_file_s3_location\"]\n",
    "input_feature_selection_file_uri = f\"s3://{input_bucket}/{feature_selection_file_name}\"\n",
    "\n",
    "# preprocessing_code_location_uri = f\"s3://{pipeline_input_bucket}/codes/Training_Preprocessing.py\"\n",
    "\n",
    "# Basic feature selection file path\n",
    "feature_selection_file = ParameterString(name = \"FeatureSelectionFile\", default_value = input_feature_selection_file_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sagemaker_session.default_bucket = pipeline_output_bucket\n",
    "\n",
    "# Creating the output bucket if it is not already present\n",
    "s3 = boto3.client('s3')\n",
    "buckets = [dictionary[\"Name\"] for dictionary in s3.list_buckets()['Buckets']]\n",
    "if pipeline_output_bucket not in buckets:\n",
    "    location = {'LocationConstraint': region}\n",
    "    response = s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration = location)\n",
    "\n",
    "\n",
    "from time import gmtime, strftime\n",
    "pipeline_start_time = strftime(\"%Y%m%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "processing_output_path = f\"s3://{pipeline_output_bucket}/Scoring_Pipeline_Output/{pipeline_start_time}/ProcessingOutput\"\n",
    "inference_output_path = f\"s3://{pipeline_output_bucket}/Scoring_Pipeline_Output/{pipeline_start_time}/InferenceOutput\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Preprocessing Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "framework_version = build_parameters[\"sklearn_processor_framework_version\"]\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=build_parameters[\"scoring_preprocessing_instance_type\"],\n",
    "    instance_count=build_parameters[\"scoring_preprocessing_instance_count\"],\n",
    "    base_job_name=\"Churn-Inference-Preprocessing\",\n",
    "    role=role\n",
    ")\n",
    "\n",
    "\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep, TuningStep\n",
    "    \n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"Preprocessing\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "      ProcessingInput(source=batch_data, destination=\"/opt/ml/processing/input\"),  \n",
    "      ProcessingInput(source=feature_selection_file, destination=\"/opt/ml/processing/input/feature_selection\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\", destination = processing_output_path),\n",
    "        ProcessingOutput(output_name = \"logs\", source=\"/opt/ml/processing/logss\", destination = processing_output_path)\n",
    "    ],\n",
    "    # code=\"SageMaker_Pipeline_Component_Codes/Scoring/Scoring_Preprocessing.py\",\n",
    "    code = f\"s3://{build_parameters['input_bucket']}/codes/{build_parameters['scoring_preprocessing_code_location'].split('/')[-1]}\",\n",
    "    job_arguments = [\"--batch_data_location\", \"/opt/ml/processing/input\", \"--target_column\", \"Churn\",\n",
    "                     \"--feature_selection_file_location\", \"/opt/ml/processing/input/feature_selection\",\n",
    "                     \"--preprocessed_batch_data_location\", \"/opt/ml/processing/train\", \"--log_location\", \"/opt/ml/processing/logss\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Model Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ModelPackageGroupName': 'churn-packagegroup', 'ModelPackageVersion': 5, 'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:852619674999:model-package/churn-packagegroup/5', 'CreationTime': datetime.datetime(2022, 6, 30, 7, 40, 14, 674000, tzinfo=tzlocal()), 'ModelPackageStatus': 'Completed', 'ModelApprovalStatus': 'PendingManualApproval'}\n",
      "arn:aws:sagemaker:us-east-1:852619674999:model-package/churn-packagegroup/5\n"
     ]
    }
   ],
   "source": [
    "#### Obtaining the model from Sagemaker model registry.\n",
    "package_group = build_parameters[\"model_package_group_name\"]\n",
    "\n",
    "import boto3\n",
    "client = boto3.client('sagemaker')\n",
    "model_packages = client.list_model_packages(ModelPackageGroupName = package_group)\n",
    "\n",
    "\n",
    "latest_package = model_packages[\"ModelPackageSummaryList\"][0]\n",
    "latest_package_arn = latest_package[\"ModelPackageArn\"]\n",
    "\n",
    "print(latest_package)\n",
    "print(latest_package_arn)\n",
    "\n",
    "\n",
    "latest_package_details = client.describe_model_package(ModelPackageName=latest_package_arn)\n",
    "\n",
    "from sagemaker.model import Model\n",
    "inference_model = Model(image_uri = latest_package_details['InferenceSpecification']['Containers'][0]['Image'], \n",
    "                        # source_dir = f\"s3://{build_parameters['input_bucket']}/codes/scoring.tar.gz\",\n",
    "                        # entry_point = f\"{build_parameters['scoring_code_location'].split('/')[-1]}\",\n",
    "                        # entry_point=\"../\" + build_parameters[\"scoring_code_loaction\"], \n",
    "                        model_data = latest_package_details['InferenceSpecification']['Containers'][0][\"ModelDataUrl\"], \n",
    "                        role = role,\n",
    "                        sagemaker_session = sagemaker_session,\n",
    "                        env = {'model_server_workers':'1',\n",
    "                              'SAGEMAKER_MODEL_SERVER_WORKERS':'1'}\n",
    "                       )\n",
    "\n",
    "\n",
    "\n",
    "from sagemaker.inputs import CreateModelInput\n",
    "\n",
    "inputs = CreateModelInput(\n",
    "    # instance_type=build_parameters[\"scoring_instance_type\"],\n",
    "    instance_type=\"ml.t3.medium\",\n",
    "    # accelerator_type=\"ml.eia1.medium\",\n",
    ")\n",
    "\n",
    "\n",
    "from sagemaker.workflow.steps import CreateModelStep\n",
    "\n",
    "step_create_model = CreateModelStep(\n",
    "    name=\"Get-Model\",\n",
    "    model=inference_model,\n",
    "    inputs=inputs,\n",
    "    depends_on  = [step_process]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Inference Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_transform = ProcessingStep(\n",
    "    name=\"Inference\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "      ProcessingInput(source=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri, destination=\"/opt/ml/processing/input/data\"),  \n",
    "      ProcessingInput(source=step_create_model.properties.PrimaryContainer.ModelDataUrl, destination=\"/opt/ml/processing/input/model_folder\"),  \n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\", destination = inference_output_path)\n",
    "    ],\n",
    "    # code=\"SageMaker_Pipeline_Component_Codes/Scoring/scoring.py\",\n",
    "    # code = f\"s3://{build_parameters['input_bucket']}/codes/{build_parameters['scoring_preprocessing_code_location'].split('/')[-1]}\",\n",
    "    code = f\"s3://{build_parameters['input_bucket']}/codes/scoring.py\",\n",
    "    job_arguments = [\"--batch_data_location\", \"/opt/ml/processing/input/data\", \n",
    "                     \"--model_location\", \"/opt/ml/processing/input/model_folder\",\n",
    "                     \"--predicted_data_location\", \"/opt/ml/processing/train\", \n",
    "                     \"--log_location\", \"/opt/ml/processing/logss\"\n",
    "                    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from sagemaker.transformer import Transformer\n",
    "\n",
    "\n",
    "# transformer = Transformer(\n",
    "#     model_name=step_create_model.properties.ModelName,\n",
    "#     instance_type=build_parameters[\"scoring_instance_type\"],\n",
    "#     instance_count=1,\n",
    "#     output_path=inference_output_path,\n",
    "#     base_transform_job_name = \"Churn-Transformation\",\n",
    "#     # max_concurrent_transforms = 1,\n",
    "#     # strategy = \"SingleRecord\"\n",
    "# )\n",
    "\n",
    "# from sagemaker.inputs import TransformInput\n",
    "# from sagemaker.workflow.steps import TransformStep\n",
    "\n",
    "\n",
    "# step_transform = TransformStep(\n",
    "#     name=\"Inference\",\n",
    "#     transformer=transformer,\n",
    "#     inputs=TransformInput(data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "#                           # data_type = \"text/csv\"\n",
    "#                          ),\n",
    "#     depends_on  = [step_process]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline_name = f\"Churn-Scoring\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        batch_data,\n",
    "        feature_selection_file\n",
    "    ],\n",
    "    steps=[step_process, \n",
    "           step_create_model, \n",
    "           step_transform\n",
    "          ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:852619674999:pipeline/churn-scoring',\n",
       " 'ResponseMetadata': {'RequestId': '58538039-fd4c-40e5-b8bb-c83eb66a1562',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '58538039-fd4c-40e5-b8bb-c83eb66a1562',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '81',\n",
       "   'date': 'Fri, 01 Jul 2022 12:36:42 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
